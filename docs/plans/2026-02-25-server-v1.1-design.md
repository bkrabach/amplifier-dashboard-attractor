# Dashboard Server v1.1 — Cancellation, SSE Events, and Human Gates

## Goal

Extend the Attractor Pipeline Dashboard server with three capabilities for production pipeline management: pipeline cancellation, SSE event streaming, and HTTP-based human-in-the-loop gates.

## Background

The dashboard server currently supports pipeline submission via `POST /api/pipelines` and background execution through the `PipelineExecutor` (Tasks 7-8 from the previous plan). These three additions complete the production control surface:

1. **Pipeline cancellation** — graceful mid-execution cancel via HTTP
2. **SSE event stream** — real-time raw pipeline events for programmatic consumers
3. **Human gate question/answer** — HTTP-based human-in-the-loop gates

All three build on the existing `PipelineExecutor` infrastructure and share a common route module (`routes/control.py`).

## Key Design Decisions

1. **Cancel completes the current node, then exits** — no mid-node interruption, which would leave inconsistent state.
2. **SSE streams raw pipeline events** — not pre-formatted state diffs. Raw events are more flexible for programmatic consumers. The dashboard frontend continues using WebSocket for its own needs.
3. **Human gates use asyncio.Event for blocking** — the `wait.human` handler registers a question with the executor, then blocks on an `asyncio.Event` until the HTTP answer endpoint signals it.

## Scope Boundaries

- All changes in the dashboard server repo (`amplifier-dashboard-attractor`)
- No changes to `amplifier-core` or the attractor bundle engine
- The `wait.human` handler integration may require a small adapter in the `PipelineExecutor` that wraps the handler's stdin path — the handler itself stays unchanged
- SSE endpoint uses standard `text/event-stream` content type — no custom protocol
- No authentication on any endpoint (dev tool)

---

## Section 1: Pipeline Cancellation

`POST /api/pipelines/{id}/cancel` sets a cancellation flag that the engine checks between node executions.

### How It Works

The `PipelineExecutor` gains a `cancel(pipeline_id)` method that sets a cancellation flag on the pipeline's tracking entry. The engine's main `run()` loop checks a `_cancelled` flag between nodes — after each node completes, before selecting the next edge. If cancelled, the engine writes a final checkpoint with `status: "cancelled"`, emits `pipeline:complete` with status cancelled, and returns.

### The Endpoint

```
POST /api/pipelines/{id}/cancel
Response: {"pipeline_id": "...", "status": "cancelling"}
```

Returns 404 if pipeline not found, 409 if already completed/failed.

Status transitions: `running` -> `cancelling` -> `cancelled`. The "cancelling" state means the cancel was requested but the current node is still finishing. The engine completes the current node (no mid-node interruption), then exits cleanly.

### Cancel Signal Path

```
POST /cancel -> PipelineExecutor.cancel(id) -> sets cancel_event
                                                    |
Engine main loop: after node complete, check cancel_event.is_set()
                                                    |
                                           Return Outcome(status="cancelled")
```

### Implementation Steps

1. Add `cancel_events: dict[str, asyncio.Event]` to `PipelineExecutor`
2. In `start_pipeline()`, create an Event for the pipeline
3. In `cancel(pipeline_id)`, set the Event and update status to "cancelling"
4. Pass the `cancel_event` to the engine (via the hooks object or a new parameter)
5. In the engine's main loop, check `cancel_event.is_set()` between nodes
6. New route: `routes/control.py` with the cancel endpoint
7. Register in `server.py`

---

## Section 2: SSE Event Stream

`GET /api/pipelines/{id}/events` returns a Server-Sent Events stream of raw pipeline events in real-time.

### How It Works

The `PipelineExecutor` maintains an `asyncio.Queue` per pipeline for events. When the engine runs, a lightweight `EventCaptureHook` captures all `pipeline:*` events and pushes them onto the queue. The SSE endpoint reads from the queue and sends each event as an SSE message.

### Event Format (SSE)

```
event: pipeline:node_start
data: {"node_id": "implement", "handler_type": "codergen", "timestamp": "2026-02-25T..."}

event: pipeline:node_complete
data: {"node_id": "implement", "status": "success", "duration_ms": 8200, "timestamp": "2026-02-25T..."}

event: pipeline:complete
data: {"status": "success", "nodes_completed": 5, "total_elapsed_ms": 45200}
```

Each SSE message has an `event:` field (the pipeline event type) and a `data:` field (the event payload as JSON). This follows the standard SSE format supported by `EventSource` in browsers and most HTTP clients.

### Event Capture Path

```
Engine hooks.emit("pipeline:node_start", data)
           |
EventCaptureHook.handle(event, data)
           |
pipeline_queue.put_nowait({"event": event, "data": data, "ts": now})
           |
SSE endpoint reads from queue, yields SSE-formatted text
```

### EventCaptureHook

```python
class EventCaptureHook:
    def __init__(self, queue: asyncio.Queue):
        self._queue = queue

    async def emit(self, event: str, data: dict) -> HookResult:
        self._queue.put_nowait({
            "event": event,
            "data": data,
            "ts": datetime.utcnow().isoformat(),
        })
        return HookResult()
```

### Connection Lifecycle

1. Client connects -> endpoint sends a `connected` event with `pipeline_id`
2. Events stream as they occur
3. When pipeline completes/fails/cancels -> endpoint sends a final `pipeline:complete` event, then closes
4. Client disconnect -> endpoint stops reading from queue (no cleanup needed — queue is GC'd with the pipeline)
5. Late connection (pipeline already running) -> sends current pipeline state as first event, then streams from current position

### Implementation Steps

1. Create `EventCaptureHook` class that pushes events to an `asyncio.Queue`
2. Add `event_queues: dict[str, asyncio.Queue]` to `PipelineExecutor`
3. In `start_pipeline()`, create a queue and `EventCaptureHook`, pass hook to engine
4. New SSE endpoint in `routes/control.py` using `StreamingResponse`
5. The SSE endpoint generator reads from the queue with timeout, yields SSE-formatted strings
6. Connection lifecycle: connect -> send "connected" event -> stream events -> send "pipeline:complete" -> close
7. Late connection: send current pipeline state as first event, then stream from current position

---

## Section 3: Human Gate Question/Answer

Two endpoints for human-in-the-loop gates — when the engine hits a `wait.human` handler (hexagon shape), it blocks until a human provides an answer via HTTP.

### How It Works

The `PipelineExecutor` maintains a pending questions dict per pipeline. When the engine reaches a human gate node, the `wait.human` handler registers a question with the executor and blocks on an `asyncio.Event`. An external client polls for pending questions and submits answers.

### The Flow

```
Engine reaches hexagon node -> wait.human handler fires
    |
Handler creates PendingQuestion (id, prompt, options)
    |
Handler registers question with PipelineExecutor.register_question(pipeline_id, question)
    |
Handler awaits question.answer_event.wait() (blocks the pipeline)
    |
External client polls GET /api/pipelines/{id}/questions -> sees pending question
    |
Client submits POST /api/pipelines/{id}/questions/{qid}/answer with answer
    |
Executor sets the answer on the PendingQuestion and signals the event
    |
Handler resumes with the answer, pipeline continues
```

### The Endpoints

```
GET /api/pipelines/{id}/questions
Response: [
  {
    "question_id": "q1",
    "node_id": "human_review",
    "prompt": "Approve changes?",
    "options": ["approve", "revise"],
    "created_at": "..."
  }
]

POST /api/pipelines/{id}/questions/{qid}/answer
Body: {"answer": "approve"}
Response: {"status": "answered"}
```

Returns 404 if pipeline or question not found. Returns 409 if question already answered.

### The PendingQuestion Model

```python
@dataclass
class PendingQuestion:
    question_id: str
    pipeline_id: str
    node_id: str
    prompt: str
    options: list[str]
    created_at: str
    answer: str | None = None
    answer_event: asyncio.Event  # signaled when answer is provided
```

### Integration with wait.human Handler

The handler currently blocks waiting for console input. For HTTP server mode, when running under the executor, it needs an alternative path. The `PipelineExecutor` provides a `question_callback` that the handler uses instead of stdin. The callback is passed through the hooks object or context.

### Implementation Steps

1. Add `PendingQuestion` dataclass to `pipeline_executor.py`
2. Add `questions: dict[str, dict[str, PendingQuestion]]` to `PipelineExecutor` (`pipeline_id` -> `question_id` -> question)
3. Add `register_question()` and `answer_question()` methods
4. New endpoints in `routes/control.py` for GET questions and POST answer
5. Create a `QuestionCallbackHook` that the engine can use to register questions
6. The `wait.human` handler checks for the callback and uses it instead of stdin when available

---

## Testing Strategy

| Item | Test Approach |
|------|---------------|
| Cancellation | **Unit:** `cancel()` sets event, `get_status` returns "cancelling". **Integration:** submit pipeline, cancel mid-execution, verify status transitions. |
| SSE stream | **Unit:** `EventCaptureHook` pushes events to queue. **Integration:** submit pipeline, connect to SSE, verify events arrive. |
| Human gates | **Unit:** `register_question`/`answer_question` lifecycle. **Integration:** submit pipeline with hexagon node, poll questions, submit answer, verify pipeline continues. |

## Open Questions

1. **SSE reconnection hint:** Should we include a `retry:` field (SSE reconnection hint) with a recommended reconnect interval? Recommended: yes, `retry: 2000` (2 seconds).
2. **Human gate timeout:** Should there be a timeout? The NLSpec mentions `approval_timeout=300.0` as a default. Recommended: yes, default 5 minutes, configurable per node via the `timeout` attribute.
