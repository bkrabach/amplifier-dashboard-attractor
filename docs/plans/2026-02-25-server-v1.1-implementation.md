# Server v1.1 Implementation Plan — Cancellation, SSE Events, Human Gates

> **Execution:** Use the subagent-driven-development workflow to implement this plan.

**Goal:** Add three HTTP control endpoints to the dashboard server: pipeline cancellation, SSE event streaming, and human gate question/answer.

**Architecture:** All three features extend `PipelineExecutor` with new tracking dicts (`cancel_events`, `event_queues`, `questions`) and expose them via a new `routes/control.py` router. Each feature follows the same pattern: add state + methods to the executor, then wire up an HTTP endpoint that calls those methods.

**Tech Stack:** Python 3.11+, FastAPI, asyncio, pytest + pytest-asyncio, httpx AsyncClient

---

## Task 1: Add cancel_events tracking and cancel() method to PipelineExecutor

**Files:**
- Modify: `amplifier_dashboard_attractor/pipeline_executor.py`
- Test: `tests/test_cancel.py` (create)

### Step 1: Write failing tests

Create `tests/test_cancel.py` with three tests that exercise the cancel lifecycle on a bare `PipelineExecutor` (no engine needed):

```python
# tests/test_cancel.py
"""Tests for pipeline cancellation."""

import asyncio

import pytest

from amplifier_dashboard_attractor.pipeline_executor import PipelineExecutor


@pytest.mark.asyncio
async def test_cancel_sets_event_and_status():
    """cancel() sets the cancel event and changes status to 'cancelling'."""
    executor = PipelineExecutor()

    # Simulate a running pipeline (manual insert — no real engine needed)
    cancel_event = asyncio.Event()
    executor.active_pipelines["p1"] = {
        "task": None,
        "status": "running",
        "logs_root": "/tmp/test",
    }
    executor.cancel_events["p1"] = cancel_event

    result = executor.cancel("p1")

    assert result is True
    assert cancel_event.is_set()
    assert executor.get_status("p1") == "cancelling"


@pytest.mark.asyncio
async def test_cancel_unknown_pipeline_returns_false():
    """cancel() returns False for unknown pipeline IDs."""
    executor = PipelineExecutor()
    assert executor.cancel("nonexistent") is False


@pytest.mark.asyncio
async def test_cancel_completed_pipeline_returns_false():
    """cancel() returns False if pipeline already completed."""
    executor = PipelineExecutor()
    executor.active_pipelines["p1"] = {
        "task": None,
        "status": "completed",
        "logs_root": "/tmp/test",
    }
    executor.cancel_events["p1"] = asyncio.Event()

    assert executor.cancel("p1") is False
```

### Step 2: Run tests — expect failure

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_cancel.py -v --tb=short
```

Expected: all 3 tests FAIL because `PipelineExecutor` has no `cancel_events` attribute or `cancel()` method.

### Step 3: Implement cancel_events + cancel() on PipelineExecutor

Open `amplifier_dashboard_attractor/pipeline_executor.py`.

**3a.** In `__init__`, add the `cancel_events` dict right after `self.active_pipelines`:

```python
    def __init__(self) -> None:
        self.active_pipelines: dict[str, dict[str, Any]] = {}
        self.cancel_events: dict[str, asyncio.Event] = {}
```

**3b.** In the `start()` method, create a cancel event for the new pipeline. Add this line right after the `self.active_pipelines[pipeline_id] = { ... }` block (after line 45):

```python
        self.cancel_events[pipeline_id] = asyncio.Event()
```

**3c.** Add the `cancel()` method right after `get_status()` (after line 108):

```python
    def cancel(self, pipeline_id: str) -> bool:
        """Request cancellation of a running pipeline.

        Returns True if cancellation was requested, False if pipeline
        not found or not in a cancellable state.
        """
        info = self.active_pipelines.get(pipeline_id)
        if info is None:
            return False
        if info["status"] != "running":
            return False
        info["status"] = "cancelling"
        cancel_event = self.cancel_events.get(pipeline_id)
        if cancel_event:
            cancel_event.set()
        return True
```

**3d.** Update `cleanup_completed()` to also clean up cancelled pipelines. Change the status check on line 118 from:

```python
            if info["status"] in ("completed", "failed")
```

to:

```python
            if info["status"] in ("completed", "failed", "cancelled")
```

And add cleanup of the cancel_events dict inside the `for pid in to_remove:` loop, right before `del self.active_pipelines[pid]`:

```python
            self.cancel_events.pop(pid, None)
```

### Step 4: Run tests — expect pass

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_cancel.py -v --tb=short
```

Expected: all 3 tests PASS.

### Step 5: Run full test suite to check for regressions

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/ -q --tb=short
```

Expected: all existing tests still pass.

### Step 6: Commit

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
git add amplifier_dashboard_attractor/pipeline_executor.py tests/test_cancel.py
git commit -m "feat: add cancel_events tracking and cancel() to PipelineExecutor"
```

---

## Task 2: Add POST /api/pipelines/{id}/cancel endpoint

**Files:**
- Create: `amplifier_dashboard_attractor/routes/control.py`
- Modify: `amplifier_dashboard_attractor/server.py`
- Test: `tests/test_cancel.py` (append)

### Step 1: Write failing endpoint tests

Append these two tests to `tests/test_cancel.py`:

```python
from httpx import ASGITransport, AsyncClient

from amplifier_dashboard_attractor.server import create_app


@pytest.fixture
def cancel_app(tmp_path):
    app = create_app(pipeline_logs_dir=str(tmp_path))
    return app


@pytest.fixture
async def cancel_client(cancel_app):
    transport = ASGITransport(app=cancel_app)
    async with AsyncClient(transport=transport, base_url="http://test") as c:
        yield c


@pytest.mark.asyncio
async def test_cancel_endpoint_not_found(cancel_client):
    """POST /api/pipelines/{id}/cancel returns 404 for unknown pipeline."""
    resp = await cancel_client.post("/api/pipelines/unknown-id/cancel")
    assert resp.status_code == 404


@pytest.mark.asyncio
async def test_cancel_endpoint_success(cancel_app, cancel_client):
    """POST /api/pipelines/{id}/cancel returns 200 with cancelling status."""
    # Manually register a fake running pipeline on the executor
    executor = cancel_app.state.pipeline_executor
    executor.active_pipelines["test-pipe"] = {
        "task": None,
        "status": "running",
        "logs_root": "/tmp/test",
    }
    executor.cancel_events["test-pipe"] = asyncio.Event()

    resp = await cancel_client.post("/api/pipelines/test-pipe/cancel")
    assert resp.status_code == 200
    body = resp.json()
    assert body["pipeline_id"] == "test-pipe"
    assert body["status"] == "cancelling"


@pytest.mark.asyncio
async def test_cancel_endpoint_conflict(cancel_app, cancel_client):
    """POST /api/pipelines/{id}/cancel returns 409 if already completed."""
    executor = cancel_app.state.pipeline_executor
    executor.active_pipelines["done-pipe"] = {
        "task": None,
        "status": "completed",
        "logs_root": "/tmp/test",
    }
    executor.cancel_events["done-pipe"] = asyncio.Event()

    resp = await cancel_client.post("/api/pipelines/done-pipe/cancel")
    assert resp.status_code == 409
```

### Step 2: Run tests — expect failure

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_cancel.py::test_cancel_endpoint_not_found tests/test_cancel.py::test_cancel_endpoint_success tests/test_cancel.py::test_cancel_endpoint_conflict -v --tb=short
```

Expected: FAIL — the `/api/pipelines/{id}/cancel` route doesn't exist yet.

### Step 3: Create routes/control.py

Create the file `amplifier_dashboard_attractor/routes/control.py`:

```python
"""Pipeline control endpoints — cancel, SSE events, human gates.

POST /api/pipelines/{pipeline_id}/cancel
GET  /api/pipelines/{pipeline_id}/events        (added in Task 4)
GET  /api/pipelines/{pipeline_id}/questions      (added in Task 6)
POST /api/pipelines/{pipeline_id}/questions/{question_id}/answer  (added in Task 6)
"""

from __future__ import annotations

from fastapi import APIRouter, HTTPException, Request

router = APIRouter(prefix="/api/pipelines", tags=["control"])


def _get_executor(request: Request):
    """Get the pipeline executor from app state, or raise 503."""
    executor = getattr(request.app.state, "pipeline_executor", None)
    if executor is None:
        raise HTTPException(status_code=503, detail="Pipeline executor not available")
    return executor


@router.post("/{pipeline_id}/cancel")
async def cancel_pipeline(request: Request, pipeline_id: str):
    """Cancel a running pipeline.

    Returns 404 if pipeline not found.
    Returns 409 if pipeline already completed/failed (not cancellable).
    Returns 200 with cancelling status on success.
    """
    executor = _get_executor(request)

    status = executor.get_status(pipeline_id)
    if status is None:
        raise HTTPException(status_code=404, detail=f"Pipeline {pipeline_id} not found")

    cancelled = executor.cancel(pipeline_id)
    if not cancelled:
        raise HTTPException(
            status_code=409,
            detail=f"Pipeline {pipeline_id} is {status}, cannot cancel",
        )

    return {"pipeline_id": pipeline_id, "status": "cancelling"}
```

### Step 4: Register the control router in server.py

Open `amplifier_dashboard_attractor/server.py`.

**4a.** Add the import at the top, after the existing router imports (after line 27):

```python
from amplifier_dashboard_attractor.routes.control import router as control_router
```

**4b.** Register the router after the existing `app.include_router(ws_router)` line (after line 75):

```python
    app.include_router(control_router)
```

### Step 5: Run tests — expect pass

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_cancel.py -v --tb=short
```

Expected: all 6 tests PASS (3 unit + 3 endpoint).

### Step 6: Run full test suite

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/ -q --tb=short
```

Expected: all tests pass.

### Step 7: Commit

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
git add amplifier_dashboard_attractor/routes/control.py amplifier_dashboard_attractor/server.py tests/test_cancel.py
git commit -m "feat: add POST /api/pipelines/{id}/cancel endpoint"
```

---

## Task 3: Add EventCaptureHook and event queue to PipelineExecutor

**Files:**
- Modify: `amplifier_dashboard_attractor/pipeline_executor.py`
- Test: `tests/test_sse_events.py` (create)

### Step 1: Write failing tests

Create `tests/test_sse_events.py` with tests for the `EventCaptureHook` class and the executor's event queue lifecycle:

```python
# tests/test_sse_events.py
"""Tests for SSE event capture and streaming."""

import asyncio
import json

import pytest

from amplifier_dashboard_attractor.pipeline_executor import (
    EventCaptureHook,
    PipelineExecutor,
)


@pytest.mark.asyncio
async def test_event_capture_hook_pushes_to_queue():
    """EventCaptureHook.emit() pushes events onto its queue."""
    queue: asyncio.Queue = asyncio.Queue()
    hook = EventCaptureHook(queue)

    await hook.emit("pipeline:node_start", {"node_id": "work"})

    assert not queue.empty()
    item = queue.get_nowait()
    assert item["event"] == "pipeline:node_start"
    assert item["data"]["node_id"] == "work"
    assert "ts" in item


@pytest.mark.asyncio
async def test_event_capture_hook_multiple_events():
    """Multiple emit() calls queue multiple events in order."""
    queue: asyncio.Queue = asyncio.Queue()
    hook = EventCaptureHook(queue)

    await hook.emit("pipeline:node_start", {"node_id": "a"})
    await hook.emit("pipeline:node_complete", {"node_id": "a"})

    assert queue.qsize() == 2
    first = queue.get_nowait()
    second = queue.get_nowait()
    assert first["event"] == "pipeline:node_start"
    assert second["event"] == "pipeline:node_complete"


@pytest.mark.asyncio
async def test_executor_creates_event_queue_on_start():
    """PipelineExecutor.start() creates an event_queue for the pipeline."""
    executor = PipelineExecutor()

    # We need to manually test that event_queues dict gets populated
    # by simulating what start() does internally
    executor.event_queues["p1"] = asyncio.Queue()

    assert "p1" in executor.event_queues
    assert isinstance(executor.event_queues["p1"], asyncio.Queue)


@pytest.mark.asyncio
async def test_get_event_queue_returns_none_for_unknown():
    """get_event_queue() returns None for unknown pipelines."""
    executor = PipelineExecutor()
    assert executor.get_event_queue("nonexistent") is None


@pytest.mark.asyncio
async def test_get_event_queue_returns_queue():
    """get_event_queue() returns the queue for a known pipeline."""
    executor = PipelineExecutor()
    q = asyncio.Queue()
    executor.event_queues["p1"] = q
    assert executor.get_event_queue("p1") is q
```

### Step 2: Run tests — expect failure

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_sse_events.py -v --tb=short
```

Expected: FAIL — `EventCaptureHook` doesn't exist, `event_queues` doesn't exist.

### Step 3: Implement EventCaptureHook and event_queues

Open `amplifier_dashboard_attractor/pipeline_executor.py`.

**3a.** Add `datetime` import at the top. Change:

```python
import asyncio
import logging
from typing import Any
```

to:

```python
import asyncio
import logging
from datetime import datetime, timezone
from typing import Any
```

**3b.** Add the `EventCaptureHook` class before the `PipelineExecutor` class (after the `logger = ...` line, before `class PipelineExecutor`):

```python


class EventCaptureHook:
    """Captures pipeline events and pushes them to an asyncio.Queue.

    Used by the SSE endpoint to stream events to connected clients.
    """

    def __init__(self, queue: asyncio.Queue) -> None:
        self._queue = queue

    async def emit(self, event: str, data: dict) -> None:
        """Push an event onto the queue."""
        self._queue.put_nowait({
            "event": event,
            "data": data,
            "ts": datetime.now(timezone.utc).isoformat(),
        })
```

**3c.** In `PipelineExecutor.__init__`, add `event_queues` after `cancel_events`:

```python
    def __init__(self) -> None:
        self.active_pipelines: dict[str, dict[str, Any]] = {}
        self.cancel_events: dict[str, asyncio.Event] = {}
        self.event_queues: dict[str, asyncio.Queue] = {}
```

**3d.** In `start()`, create an event queue for the pipeline. Add this line right after the `self.cancel_events[pipeline_id] = ...` line:

```python
        self.event_queues[pipeline_id] = asyncio.Queue()
```

**3e.** Add the `get_event_queue()` method after the `cancel()` method:

```python
    def get_event_queue(self, pipeline_id: str) -> asyncio.Queue | None:
        """Get the event queue for a pipeline, or None if not found."""
        return self.event_queues.get(pipeline_id)
```

**3f.** Update `cleanup_completed()` to also clean up event_queues. In the `for pid in to_remove:` loop, add right after the `cancel_events.pop(...)` line:

```python
            self.event_queues.pop(pid, None)
```

### Step 4: Run tests — expect pass

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_sse_events.py -v --tb=short
```

Expected: all 5 tests PASS.

### Step 5: Run full test suite

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/ -q --tb=short
```

Expected: all tests pass.

### Step 6: Commit

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
git add amplifier_dashboard_attractor/pipeline_executor.py tests/test_sse_events.py
git commit -m "feat: add EventCaptureHook and event_queues to PipelineExecutor"
```

---

## Task 4: Add GET /api/pipelines/{id}/events SSE endpoint

**Files:**
- Modify: `amplifier_dashboard_attractor/routes/control.py`
- Test: `tests/test_sse_events.py` (append)

### Step 1: Write failing endpoint tests

Append these tests to `tests/test_sse_events.py`:

```python
from httpx import ASGITransport, AsyncClient

from amplifier_dashboard_attractor.server import create_app


@pytest.fixture
def sse_app(tmp_path):
    return create_app(pipeline_logs_dir=str(tmp_path))


@pytest.fixture
async def sse_client(sse_app):
    transport = ASGITransport(app=sse_app)
    async with AsyncClient(transport=transport, base_url="http://test") as c:
        yield c


@pytest.mark.asyncio
async def test_sse_endpoint_not_found(sse_client):
    """GET /api/pipelines/{id}/events returns 404 for unknown pipeline."""
    resp = await sse_client.get("/api/pipelines/unknown-id/events")
    assert resp.status_code == 404


@pytest.mark.asyncio
async def test_sse_endpoint_streams_events(sse_app):
    """GET /api/pipelines/{id}/events streams SSE events from the queue."""
    executor = sse_app.state.pipeline_executor

    # Register a fake pipeline with an event queue
    queue = asyncio.Queue()
    executor.active_pipelines["sse-pipe"] = {
        "task": None,
        "status": "running",
        "logs_root": "/tmp/test",
    }
    executor.event_queues["sse-pipe"] = queue
    executor.cancel_events["sse-pipe"] = asyncio.Event()

    # Pre-load events into the queue
    queue.put_nowait({
        "event": "pipeline:node_start",
        "data": {"node_id": "work"},
        "ts": "2026-02-25T00:00:00",
    })
    queue.put_nowait({
        "event": "pipeline:complete",
        "data": {"status": "success"},
        "ts": "2026-02-25T00:00:01",
    })

    transport = ASGITransport(app=sse_app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        # Use stream to read the SSE response
        async with client.stream("GET", "/api/pipelines/sse-pipe/events") as resp:
            assert resp.status_code == 200
            assert "text/event-stream" in resp.headers["content-type"]

            lines = []
            async for line in resp.aiter_lines():
                lines.append(line)
                # Stop after we see the pipeline:complete event
                if "pipeline:complete" in line and line.startswith("event:"):
                    # Read the data line too
                    async for next_line in resp.aiter_lines():
                        lines.append(next_line)
                        if next_line.startswith("data:"):
                            break
                    break

    # Verify we got SSE-formatted events
    text = "\n".join(lines)
    assert "event: connected" in text or "event: pipeline:node_start" in text
    assert "event: pipeline:complete" in text
```

### Step 2: Run tests — expect failure

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_sse_events.py::test_sse_endpoint_not_found tests/test_sse_events.py::test_sse_endpoint_streams_events -v --tb=short
```

Expected: FAIL — the `/api/pipelines/{id}/events` route doesn't exist yet.

### Step 3: Add SSE endpoint to routes/control.py

Open `amplifier_dashboard_attractor/routes/control.py`.

**3a.** Update the imports at the top of the file. Change:

```python
from fastapi import APIRouter, HTTPException, Request
```

to:

```python
import asyncio
import json

from fastapi import APIRouter, HTTPException, Request
from starlette.responses import StreamingResponse
```

**3b.** Add the SSE endpoint after the `cancel_pipeline` function:

```python
@router.get("/{pipeline_id}/events")
async def pipeline_events(request: Request, pipeline_id: str):
    """Stream pipeline events as Server-Sent Events.

    Returns 404 if pipeline not found.
    Streams SSE-formatted events from the pipeline's event queue.
    Closes when pipeline completes, fails, or is cancelled.
    """
    executor = _get_executor(request)

    status = executor.get_status(pipeline_id)
    if status is None:
        raise HTTPException(status_code=404, detail=f"Pipeline {pipeline_id} not found")

    queue = executor.get_event_queue(pipeline_id)
    if queue is None:
        raise HTTPException(status_code=404, detail=f"No event stream for {pipeline_id}")

    async def event_generator():
        """Yield SSE-formatted strings from the event queue."""
        # Send initial connected event
        yield f"event: connected\ndata: {json.dumps({'pipeline_id': pipeline_id})}\nretry: 2000\n\n"

        while True:
            try:
                item = await asyncio.wait_for(queue.get(), timeout=30.0)
            except asyncio.TimeoutError:
                # Send keepalive comment
                yield ": keepalive\n\n"
                continue

            event_type = item["event"]
            data = json.dumps(item["data"])
            yield f"event: {event_type}\ndata: {data}\n\n"

            # Close stream on terminal events
            if event_type == "pipeline:complete":
                return

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )
```

### Step 4: Run tests — expect pass

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_sse_events.py -v --tb=short
```

Expected: all 7 tests PASS (5 unit + 2 endpoint).

### Step 5: Run full test suite

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/ -q --tb=short
```

Expected: all tests pass.

### Step 6: Commit

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
git add amplifier_dashboard_attractor/routes/control.py tests/test_sse_events.py
git commit -m "feat: add GET /api/pipelines/{id}/events SSE endpoint"
```

---

## Task 5: Add PendingQuestion model and register/answer methods to PipelineExecutor

**Files:**
- Modify: `amplifier_dashboard_attractor/pipeline_executor.py`
- Test: `tests/test_human_gates.py` (create)

### Step 1: Write failing tests

Create `tests/test_human_gates.py`:

```python
# tests/test_human_gates.py
"""Tests for human gate question/answer lifecycle."""

import asyncio

import pytest

from amplifier_dashboard_attractor.pipeline_executor import (
    PendingQuestion,
    PipelineExecutor,
)


@pytest.mark.asyncio
async def test_pending_question_creation():
    """PendingQuestion is created with correct fields."""
    q = PendingQuestion(
        question_id="q1",
        pipeline_id="p1",
        node_id="review",
        prompt="Approve changes?",
        options=["approve", "revise"],
        created_at="2026-02-25T00:00:00",
    )
    assert q.question_id == "q1"
    assert q.answer is None
    assert isinstance(q.answer_event, asyncio.Event)
    assert not q.answer_event.is_set()


@pytest.mark.asyncio
async def test_register_question():
    """register_question() stores the question and it's retrievable."""
    executor = PipelineExecutor()
    executor.active_pipelines["p1"] = {
        "task": None,
        "status": "running",
        "logs_root": "/tmp/test",
    }

    q = PendingQuestion(
        question_id="q1",
        pipeline_id="p1",
        node_id="review",
        prompt="Approve?",
        options=["yes", "no"],
        created_at="2026-02-25T00:00:00",
    )
    executor.register_question("p1", q)

    questions = executor.get_questions("p1")
    assert len(questions) == 1
    assert questions[0].question_id == "q1"


@pytest.mark.asyncio
async def test_answer_question_sets_answer_and_signals():
    """answer_question() sets the answer and signals the event."""
    executor = PipelineExecutor()
    executor.active_pipelines["p1"] = {
        "task": None,
        "status": "running",
        "logs_root": "/tmp/test",
    }

    q = PendingQuestion(
        question_id="q1",
        pipeline_id="p1",
        node_id="review",
        prompt="Approve?",
        options=["yes", "no"],
        created_at="2026-02-25T00:00:00",
    )
    executor.register_question("p1", q)

    result = executor.answer_question("p1", "q1", "yes")
    assert result is True
    assert q.answer == "yes"
    assert q.answer_event.is_set()


@pytest.mark.asyncio
async def test_answer_question_unknown_pipeline():
    """answer_question() returns False for unknown pipeline."""
    executor = PipelineExecutor()
    assert executor.answer_question("nonexistent", "q1", "yes") is False


@pytest.mark.asyncio
async def test_answer_question_unknown_question():
    """answer_question() returns False for unknown question ID."""
    executor = PipelineExecutor()
    executor.questions["p1"] = {}
    assert executor.answer_question("p1", "nonexistent", "yes") is False


@pytest.mark.asyncio
async def test_answer_question_already_answered():
    """answer_question() returns False if already answered."""
    executor = PipelineExecutor()

    q = PendingQuestion(
        question_id="q1",
        pipeline_id="p1",
        node_id="review",
        prompt="Approve?",
        options=["yes", "no"],
        created_at="2026-02-25T00:00:00",
    )
    q.answer = "yes"  # already answered
    q.answer_event.set()
    executor.questions["p1"] = {"q1": q}

    assert executor.answer_question("p1", "q1", "no") is False


@pytest.mark.asyncio
async def test_get_questions_unknown_pipeline():
    """get_questions() returns empty list for unknown pipeline."""
    executor = PipelineExecutor()
    assert executor.get_questions("nonexistent") == []
```

### Step 2: Run tests — expect failure

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_human_gates.py -v --tb=short
```

Expected: FAIL — `PendingQuestion` doesn't exist, `questions` attribute doesn't exist.

### Step 3: Implement PendingQuestion and question methods

Open `amplifier_dashboard_attractor/pipeline_executor.py`.

**3a.** Add `dataclass` and `field` imports. Change:

```python
from __future__ import annotations

import asyncio
import logging
from datetime import datetime, timezone
from typing import Any
```

to:

```python
from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any
```

**3b.** Add the `PendingQuestion` dataclass after the `EventCaptureHook` class (before `class PipelineExecutor`):

```python


@dataclass
class PendingQuestion:
    """A human gate question awaiting an answer.

    The answer_event is signaled when an answer is provided,
    allowing the blocked pipeline handler to resume.
    """

    question_id: str
    pipeline_id: str
    node_id: str
    prompt: str
    options: list[str]
    created_at: str
    answer: str | None = None
    answer_event: asyncio.Event = field(default_factory=asyncio.Event)
```

**3c.** In `PipelineExecutor.__init__`, add `questions` after `event_queues`:

```python
    def __init__(self) -> None:
        self.active_pipelines: dict[str, dict[str, Any]] = {}
        self.cancel_events: dict[str, asyncio.Event] = {}
        self.event_queues: dict[str, asyncio.Queue] = {}
        self.questions: dict[str, dict[str, PendingQuestion]] = {}
```

**3d.** Add the three question methods after `get_event_queue()`:

```python
    def register_question(self, pipeline_id: str, question: PendingQuestion) -> None:
        """Register a pending question for a pipeline."""
        if pipeline_id not in self.questions:
            self.questions[pipeline_id] = {}
        self.questions[pipeline_id][question.question_id] = question

    def get_questions(self, pipeline_id: str) -> list[PendingQuestion]:
        """Get all pending (unanswered) questions for a pipeline."""
        pipeline_questions = self.questions.get(pipeline_id, {})
        return [q for q in pipeline_questions.values() if q.answer is None]

    def answer_question(
        self, pipeline_id: str, question_id: str, answer: str
    ) -> bool:
        """Answer a pending question.

        Returns True if the answer was accepted, False if the question
        was not found or already answered.
        """
        pipeline_questions = self.questions.get(pipeline_id)
        if pipeline_questions is None:
            return False
        question = pipeline_questions.get(question_id)
        if question is None:
            return False
        if question.answer is not None:
            return False
        question.answer = answer
        question.answer_event.set()
        return True
```

**3e.** Update `cleanup_completed()`. In the `for pid in to_remove:` loop, add after the `event_queues.pop(...)` line:

```python
            self.questions.pop(pid, None)
```

### Step 4: Run tests — expect pass

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_human_gates.py -v --tb=short
```

Expected: all 7 tests PASS.

### Step 5: Run full test suite

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/ -q --tb=short
```

Expected: all tests pass.

### Step 6: Commit

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
git add amplifier_dashboard_attractor/pipeline_executor.py tests/test_human_gates.py
git commit -m "feat: add PendingQuestion model and question methods to PipelineExecutor"
```

---

## Task 6: Add GET/POST question/answer endpoints

**Files:**
- Modify: `amplifier_dashboard_attractor/routes/control.py`
- Test: `tests/test_human_gates.py` (append)

### Step 1: Write failing endpoint tests

Append these tests to `tests/test_human_gates.py`:

```python
from httpx import ASGITransport, AsyncClient

from amplifier_dashboard_attractor.server import create_app


@pytest.fixture
def gate_app(tmp_path):
    return create_app(pipeline_logs_dir=str(tmp_path))


@pytest.fixture
async def gate_client(gate_app):
    transport = ASGITransport(app=gate_app)
    async with AsyncClient(transport=transport, base_url="http://test") as c:
        yield c


def _register_fake_pipeline_with_question(app, pipeline_id="gate-pipe", question_id="q1"):
    """Helper: register a fake running pipeline with a pending question."""
    executor = app.state.pipeline_executor
    executor.active_pipelines[pipeline_id] = {
        "task": None,
        "status": "running",
        "logs_root": "/tmp/test",
    }
    executor.cancel_events[pipeline_id] = asyncio.Event()
    executor.event_queues[pipeline_id] = asyncio.Queue()

    q = PendingQuestion(
        question_id=question_id,
        pipeline_id=pipeline_id,
        node_id="human_review",
        prompt="Approve changes?",
        options=["approve", "revise"],
        created_at="2026-02-25T00:00:00",
    )
    executor.register_question(pipeline_id, q)
    return q


@pytest.mark.asyncio
async def test_get_questions_endpoint_not_found(gate_client):
    """GET /api/pipelines/{id}/questions returns 404 for unknown pipeline."""
    resp = await gate_client.get("/api/pipelines/unknown-id/questions")
    assert resp.status_code == 404


@pytest.mark.asyncio
async def test_get_questions_endpoint_returns_pending(gate_app, gate_client):
    """GET /api/pipelines/{id}/questions returns pending questions."""
    _register_fake_pipeline_with_question(gate_app)

    resp = await gate_client.get("/api/pipelines/gate-pipe/questions")
    assert resp.status_code == 200
    body = resp.json()
    assert len(body) == 1
    assert body[0]["question_id"] == "q1"
    assert body[0]["prompt"] == "Approve changes?"
    assert body[0]["options"] == ["approve", "revise"]
    assert "answer_event" not in body[0]  # internal field not serialized


@pytest.mark.asyncio
async def test_answer_question_endpoint_success(gate_app, gate_client):
    """POST /api/pipelines/{id}/questions/{qid}/answer answers the question."""
    q = _register_fake_pipeline_with_question(gate_app)

    resp = await gate_client.post(
        "/api/pipelines/gate-pipe/questions/q1/answer",
        json={"answer": "approve"},
    )
    assert resp.status_code == 200
    body = resp.json()
    assert body["status"] == "answered"

    # Verify the question object was updated
    assert q.answer == "approve"
    assert q.answer_event.is_set()


@pytest.mark.asyncio
async def test_answer_question_endpoint_not_found(gate_client):
    """POST answer for unknown pipeline returns 404."""
    resp = await gate_client.post(
        "/api/pipelines/unknown/questions/q1/answer",
        json={"answer": "yes"},
    )
    assert resp.status_code == 404


@pytest.mark.asyncio
async def test_answer_question_endpoint_conflict(gate_app, gate_client):
    """POST answer for already-answered question returns 409."""
    q = _register_fake_pipeline_with_question(gate_app)
    q.answer = "approve"
    q.answer_event.set()

    resp = await gate_client.post(
        "/api/pipelines/gate-pipe/questions/q1/answer",
        json={"answer": "revise"},
    )
    assert resp.status_code == 409
```

### Step 2: Run tests — expect failure

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_human_gates.py::test_get_questions_endpoint_not_found tests/test_human_gates.py::test_get_questions_endpoint_returns_pending tests/test_human_gates.py::test_answer_question_endpoint_success tests/test_human_gates.py::test_answer_question_endpoint_not_found tests/test_human_gates.py::test_answer_question_endpoint_conflict -v --tb=short
```

Expected: FAIL — the question endpoints don't exist yet.

### Step 3: Add question/answer endpoints to routes/control.py

Open `amplifier_dashboard_attractor/routes/control.py`.

**3a.** Add Pydantic import for the answer request body. Add after the existing imports:

```python
from pydantic import BaseModel
```

**3b.** Add the answer request model after the `_get_executor` helper:

```python
class AnswerBody(BaseModel):
    """Request body for answering a human gate question."""

    answer: str
```

**3c.** Add the two endpoints after the `pipeline_events` function:

```python
@router.get("/{pipeline_id}/questions")
async def get_questions(request: Request, pipeline_id: str):
    """List pending (unanswered) questions for a pipeline.

    Returns 404 if pipeline not found.
    """
    executor = _get_executor(request)

    status = executor.get_status(pipeline_id)
    if status is None:
        raise HTTPException(status_code=404, detail=f"Pipeline {pipeline_id} not found")

    questions = executor.get_questions(pipeline_id)
    return [
        {
            "question_id": q.question_id,
            "node_id": q.node_id,
            "prompt": q.prompt,
            "options": q.options,
            "created_at": q.created_at,
        }
        for q in questions
    ]


@router.post("/{pipeline_id}/questions/{question_id}/answer")
async def answer_question(
    request: Request,
    pipeline_id: str,
    question_id: str,
    body: AnswerBody,
):
    """Answer a pending human gate question.

    Returns 404 if pipeline or question not found.
    Returns 409 if question already answered.
    """
    executor = _get_executor(request)

    status = executor.get_status(pipeline_id)
    if status is None:
        raise HTTPException(status_code=404, detail=f"Pipeline {pipeline_id} not found")

    answered = executor.answer_question(pipeline_id, question_id, body.answer)
    if not answered:
        # Determine whether 404 or 409
        pipeline_questions = executor.questions.get(pipeline_id, {})
        question = pipeline_questions.get(question_id)
        if question is None:
            raise HTTPException(
                status_code=404,
                detail=f"Question {question_id} not found",
            )
        raise HTTPException(
            status_code=409,
            detail=f"Question {question_id} already answered",
        )

    return {"status": "answered"}
```

### Step 4: Run tests — expect pass

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/test_human_gates.py -v --tb=short
```

Expected: all 12 tests PASS (7 unit + 5 endpoint).

### Step 5: Run full test suite

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
uv run pytest tests/ -q --tb=short
```

Expected: all tests pass.

### Step 6: Commit

```bash
cd /home/bkrabach/dev/attractor-next/amplifier-dashboard-attractor
git add amplifier_dashboard_attractor/routes/control.py tests/test_human_gates.py
git commit -m "feat: add human gate question/answer endpoints"
```

---

## Summary

| Task | Feature | Files Changed | Tests Added |
|------|---------|--------------|-------------|
| 1 | Cancel — executor methods | `pipeline_executor.py` | `test_cancel.py` (3 tests) |
| 2 | Cancel — HTTP endpoint | `routes/control.py` (new), `server.py` | `test_cancel.py` (+3 tests) |
| 3 | SSE — hook + queue | `pipeline_executor.py` | `test_sse_events.py` (5 tests) |
| 4 | SSE — HTTP endpoint | `routes/control.py` | `test_sse_events.py` (+2 tests) |
| 5 | Human gates — model + methods | `pipeline_executor.py` | `test_human_gates.py` (7 tests) |
| 6 | Human gates — HTTP endpoints | `routes/control.py` | `test_human_gates.py` (+5 tests) |

**Total: 6 tasks, 6 commits, 25 tests**

### Final file states after all tasks:

- `amplifier_dashboard_attractor/pipeline_executor.py` — gains `EventCaptureHook`, `PendingQuestion`, `cancel_events`, `event_queues`, `questions`, and their methods
- `amplifier_dashboard_attractor/routes/control.py` — NEW file with 4 endpoints: cancel, SSE events, get questions, answer question
- `amplifier_dashboard_attractor/server.py` — one new import + one `include_router` call
- `tests/test_cancel.py` — NEW (6 tests)
- `tests/test_sse_events.py` — NEW (7 tests)
- `tests/test_human_gates.py` — NEW (12 tests)
